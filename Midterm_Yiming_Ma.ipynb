{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XRQyn2vdGM_9"
      },
      "outputs": [],
      "source": [
        "#Import Python Libraries\n",
        "import numpy as np\n",
        "import scipy as sp \n",
        "import pandas as pd \n",
        "import matplotlib as mpl \n",
        "import seaborn as sns\n",
        "from matplotlib import pyplot as plt \n",
        "\n",
        "%matplotlib inline\n",
        "from scipy import stats\n",
        "\n",
        "# use seaborn plotting defaults\n",
        "import seaborn as sns; sns.set()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JLXaHijDlnH9"
      },
      "source": [
        "1.  Import the spam dataset and print the first six rows.  "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 77
        },
        "id": "Ab2lW7xslXu4",
        "outputId": "49fdb403-17e1-445e-b2ef-76b7016b0660"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-9d11902f-129d-4945-b4b2-ded37c46eb7a\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-9d11902f-129d-4945-b4b2-ded37c46eb7a\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Saving spam_dataset.csv to spam_dataset (1).csv\n"
          ]
        }
      ],
      "source": [
        "#Read in the file and the data set\n",
        "from google.colab import files\n",
        "uploaded = files.upload()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rbJ1iZZXG8bw"
      },
      "outputs": [],
      "source": [
        "import io\n",
        "df = pd.read_csv(io.BytesIO(uploaded['spam_dataset.csv']))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 331
        },
        "id": "PxMqoStZHS6J",
        "outputId": "88174eee-bbd5-4344-80cd-7844e27312c1"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-13752cb5-ec80-47f8-a505-3e8d68a20562\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>word_freq_make:</th>\n",
              "      <th>word_freq_address:</th>\n",
              "      <th>word_freq_all:</th>\n",
              "      <th>word_freq_3d:</th>\n",
              "      <th>word_freq_our:</th>\n",
              "      <th>word_freq_over:</th>\n",
              "      <th>word_freq_remove:</th>\n",
              "      <th>word_freq_internet:</th>\n",
              "      <th>word_freq_order:</th>\n",
              "      <th>word_freq_mail:</th>\n",
              "      <th>...</th>\n",
              "      <th>char_freq_;:</th>\n",
              "      <th>char_freq_(:</th>\n",
              "      <th>char_freq_[:</th>\n",
              "      <th>char_freq_!:</th>\n",
              "      <th>char_freq_$:</th>\n",
              "      <th>char_freq_#:</th>\n",
              "      <th>capital_run_length_average:</th>\n",
              "      <th>capital_run_length_longest:</th>\n",
              "      <th>capital_run_length_total:</th>\n",
              "      <th>spam</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.00</td>\n",
              "      <td>0.64</td>\n",
              "      <td>0.64</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.32</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>...</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.778</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>3.756</td>\n",
              "      <td>61</td>\n",
              "      <td>278</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.21</td>\n",
              "      <td>0.28</td>\n",
              "      <td>0.50</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.14</td>\n",
              "      <td>0.28</td>\n",
              "      <td>0.21</td>\n",
              "      <td>0.07</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.94</td>\n",
              "      <td>...</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.132</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.372</td>\n",
              "      <td>0.180</td>\n",
              "      <td>0.048</td>\n",
              "      <td>5.114</td>\n",
              "      <td>101</td>\n",
              "      <td>1028</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.06</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.71</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.23</td>\n",
              "      <td>0.19</td>\n",
              "      <td>0.19</td>\n",
              "      <td>0.12</td>\n",
              "      <td>0.64</td>\n",
              "      <td>0.25</td>\n",
              "      <td>...</td>\n",
              "      <td>0.01</td>\n",
              "      <td>0.143</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.276</td>\n",
              "      <td>0.184</td>\n",
              "      <td>0.010</td>\n",
              "      <td>9.821</td>\n",
              "      <td>485</td>\n",
              "      <td>2259</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.63</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.31</td>\n",
              "      <td>0.63</td>\n",
              "      <td>0.31</td>\n",
              "      <td>0.63</td>\n",
              "      <td>...</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.137</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.137</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>3.537</td>\n",
              "      <td>40</td>\n",
              "      <td>191</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.63</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.31</td>\n",
              "      <td>0.63</td>\n",
              "      <td>0.31</td>\n",
              "      <td>0.63</td>\n",
              "      <td>...</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.135</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.135</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>3.537</td>\n",
              "      <td>40</td>\n",
              "      <td>191</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.85</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>1.85</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>...</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.223</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>0.000</td>\n",
              "      <td>3.000</td>\n",
              "      <td>15</td>\n",
              "      <td>54</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>6 rows × 58 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-13752cb5-ec80-47f8-a505-3e8d68a20562')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-13752cb5-ec80-47f8-a505-3e8d68a20562 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-13752cb5-ec80-47f8-a505-3e8d68a20562');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "   word_freq_make:  word_freq_address:  word_freq_all:  word_freq_3d:  \\\n",
              "0             0.00                0.64            0.64            0.0   \n",
              "1             0.21                0.28            0.50            0.0   \n",
              "2             0.06                0.00            0.71            0.0   \n",
              "3             0.00                0.00            0.00            0.0   \n",
              "4             0.00                0.00            0.00            0.0   \n",
              "5             0.00                0.00            0.00            0.0   \n",
              "\n",
              "   word_freq_our:  word_freq_over:  word_freq_remove:  word_freq_internet:  \\\n",
              "0            0.32             0.00               0.00                 0.00   \n",
              "1            0.14             0.28               0.21                 0.07   \n",
              "2            1.23             0.19               0.19                 0.12   \n",
              "3            0.63             0.00               0.31                 0.63   \n",
              "4            0.63             0.00               0.31                 0.63   \n",
              "5            1.85             0.00               0.00                 1.85   \n",
              "\n",
              "   word_freq_order:  word_freq_mail:  ...  char_freq_;:  char_freq_(:  \\\n",
              "0              0.00             0.00  ...          0.00         0.000   \n",
              "1              0.00             0.94  ...          0.00         0.132   \n",
              "2              0.64             0.25  ...          0.01         0.143   \n",
              "3              0.31             0.63  ...          0.00         0.137   \n",
              "4              0.31             0.63  ...          0.00         0.135   \n",
              "5              0.00             0.00  ...          0.00         0.223   \n",
              "\n",
              "   char_freq_[:  char_freq_!:  char_freq_$:  char_freq_#:  \\\n",
              "0           0.0         0.778         0.000         0.000   \n",
              "1           0.0         0.372         0.180         0.048   \n",
              "2           0.0         0.276         0.184         0.010   \n",
              "3           0.0         0.137         0.000         0.000   \n",
              "4           0.0         0.135         0.000         0.000   \n",
              "5           0.0         0.000         0.000         0.000   \n",
              "\n",
              "   capital_run_length_average:  capital_run_length_longest:  \\\n",
              "0                        3.756                           61   \n",
              "1                        5.114                          101   \n",
              "2                        9.821                          485   \n",
              "3                        3.537                           40   \n",
              "4                        3.537                           40   \n",
              "5                        3.000                           15   \n",
              "\n",
              "   capital_run_length_total:  spam  \n",
              "0                        278     1  \n",
              "1                       1028     1  \n",
              "2                       2259     1  \n",
              "3                        191     1  \n",
              "4                        191     1  \n",
              "5                         54     1  \n",
              "\n",
              "[6 rows x 58 columns]"
            ]
          },
          "execution_count": 18,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df.head(6)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y9wCa4ullr03"
      },
      "source": [
        "2.  Read through the documentation of the original dataset here:\n",
        "\n",
        "http://archive.ics.uci.edu/ml/machine-learning-databases/spambase/spambase.names\n",
        "\n",
        "The dependent variable is \"spam\" where one indicates that an email is spam and zero otherwise.  Which three variables in the dataset do you think will be important predictors in a model of spam?  Why?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TKVcbGTqI56Y"
      },
      "source": [
        "The three variables \"word_freq_order:\", \"\"word_freq_free:\", and \"\"word_freq_credit:\" might be important predictors in a model of spam as I think they might include \"order\", \"free\", \"credit\" frequently in their emails. \n",
        "\n",
        "\"order\": Since spam concept includes advertisement for product/web, I think they might want the reader to purchase their products by making an order. So the word \"order\" might appear frequently.\n",
        "\n",
        "\"free\": Spam might attract the reader to read or make purchases by giving them free gift, free shipping, etc. So the word \"free\" might appear frequently.\n",
        "\n",
        "\"credit\": Spam might attract the reader to make purchases by giving them extra credits which can be used in the future, or helping increase their credit by some methods. So the word \"credit\" might appear frequently."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gohGeBmHlvfy"
      },
      "source": [
        "3.  Visualize the univariate distribution of each of the variables in the previous question.  "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 447
        },
        "id": "7rw6Y9YolvxO",
        "outputId": "7980ce5d-e7fe-4cda-d9cd-bc0169a7aa1a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "count    4601.000000\n",
            "mean        0.090067\n",
            "std         0.278616\n",
            "min         0.000000\n",
            "25%         0.000000\n",
            "50%         0.000000\n",
            "75%         0.000000\n",
            "max         5.260000\n",
            "Name: word_freq_order:, dtype: float64\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x7f4c77ae3390>"
            ]
          },
          "execution_count": 19,
          "metadata": {},
          "output_type": "execute_result"
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "print(df['word_freq_order:'].describe())\n",
        "df['word_freq_order:'].hist()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 447
        },
        "id": "WRYNdXOtLTnF",
        "outputId": "2ab6dba1-e4bf-4204-f517-3e37d953f2ad"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "count    4601.000000\n",
            "mean        0.248848\n",
            "std         0.825792\n",
            "min         0.000000\n",
            "25%         0.000000\n",
            "50%         0.000000\n",
            "75%         0.100000\n",
            "max        20.000000\n",
            "Name: word_freq_free:, dtype: float64\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x7f4c77a6ad90>"
            ]
          },
          "execution_count": 20,
          "metadata": {},
          "output_type": "execute_result"
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "print(df['word_freq_free:'].describe())\n",
        "df['word_freq_free:'].hist()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 447
        },
        "id": "ljCC7Y7hLT4M",
        "outputId": "b43e92dc-a68a-4a20-a1db-a1217e3c4194"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "count    4601.000000\n",
            "mean        0.085577\n",
            "std         0.509767\n",
            "min         0.000000\n",
            "25%         0.000000\n",
            "50%         0.000000\n",
            "75%         0.000000\n",
            "max        18.180000\n",
            "Name: word_freq_credit:, dtype: float64\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x7f4c77a6a190>"
            ]
          },
          "execution_count": 21,
          "metadata": {},
          "output_type": "execute_result"
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "print(df['word_freq_credit:'].describe())\n",
        "df['word_freq_credit:'].hist()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9T6LFn_0lv-7"
      },
      "source": [
        "4. Name each of the supervised learning models that we have learned thus far that are used to predict dependent variables like \"spam\".   "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CYKPPrgSn3UU"
      },
      "source": [
        "If we want to focus on supervised learning models in classification:\n",
        "1. K Nearest Neighbors\n",
        "2. Logistic Regression\n",
        "3. Random Forest\n",
        "4. Decision Tree\n",
        "5. Support Vector Machines\n",
        "6. Bagging"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JzHnmTNWlwqD"
      },
      "source": [
        "5. Describe the importance of training and test data.  Why do we separate data into these subsets?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "09b8hAvwpq73"
      },
      "source": [
        "When we try to learn something, we split our data into two subsets: training data and test data. They play different role in Machine Learning, but both of them are important for us to learn the dataset. Training data is used to train or fit the model, while testing data is used to check how accurate the model is."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SPNp7y6YlxI8"
      },
      "source": [
        "6. What is k-fold cross validation and what do we use it for?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3ALcsMZlM_bC"
      },
      "source": [
        "k-fold cross validation: Split the observation into k subset randomly. Each subset can be used as a test data set. When a specific subset is used as a test set, the other k-1 subsets can be treated as a training data set. Then we can fit model on the training data set, and test the model with the test data set. \n",
        "\n",
        "We use k-fold cross validation as it provides us a less biased estimate of the model compare to simple split method. \n",
        "\n",
        "(https://machinelearningmastery.com/k-fold-cross-validation/)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wq0vFDDXlyR_"
      },
      "source": [
        "7. How is k-fold cross validation different from stratified k-fold cross validation?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PtUBd6ennP66"
      },
      "source": [
        "Stratified: Ensure relative class frequencies in each fold reflect relative class frequencies on the whole dataset. (Class 3 slides: Intro to supervised learning)\n",
        "\n",
        "Instead of doing random sampling, stratified k-fold cross validation uses stratified sampling."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AEBNxVmmmJjh"
      },
      "source": [
        "8. Choose one model from question four.  Split the data into training and test subsets.  Build a model with the three variables in the dataset that you think will be good predictors of \"spam\".  Describe why you chose any particular parameters for your model (e.g.- if you used KNN how did you decide to choose a specific value for k).  Run the model and evaluate prediction error in two ways: A) On test data directly and B) using k-fold cross-validation."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ryo9wS9HmJzY",
        "outputId": "34c67da8-f107-46e1-ba4a-8d0e3d80ceac"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0       1\n",
            "1       1\n",
            "2       1\n",
            "3       1\n",
            "4       1\n",
            "       ..\n",
            "4596    0\n",
            "4597    0\n",
            "4598    0\n",
            "4599    0\n",
            "4600    0\n",
            "Name: spam, Length: 4601, dtype: int64\n",
            "      word_freq_order:  word_freq_free:  word_freq_credit:\n",
            "0                 0.00             0.32               0.00\n",
            "1                 0.00             0.14               0.00\n",
            "2                 0.64             0.06               0.32\n",
            "3                 0.31             0.31               0.00\n",
            "4                 0.31             0.31               0.00\n",
            "...                ...              ...                ...\n",
            "4596              0.00             0.00               0.00\n",
            "4597              0.00             0.00               0.00\n",
            "4598              0.00             0.00               0.00\n",
            "4599              0.00             0.00               0.00\n",
            "4600              0.00             0.00               0.00\n",
            "\n",
            "[4601 rows x 3 columns]\n"
          ]
        }
      ],
      "source": [
        "# Split the data into training and test subset\n",
        "y = df['spam']\n",
        "print(y)\n",
        "\n",
        "X = df.loc[:, lambda df:[\"word_freq_order:\",\"word_freq_free:\",\"word_freq_credit:\"]]\n",
        "print(X)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "34TZWlgPNgLP",
        "outputId": "78d01c41-a4dd-4e31-a1c1-e578f4bdf379"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(4601, 3)\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "(3450, 3)"
            ]
          },
          "execution_count": 23,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Train test split\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Use train_test_split(X,y) to create four new data sets, defaults to .75/.25 split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y)\n",
        "\n",
        "print(X.shape)\n",
        "X_train.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "53uxhp26NoVh",
        "outputId": "e4eea4cb-761c-4cde-f0e9-05ff0d04b9f8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "k = 5, knn score= 0.3831450912250217\n",
            "k = 10, knn score = 0.8192875760208514\n",
            "k = 15, knn score = 0.8158123370981755\n"
          ]
        }
      ],
      "source": [
        "# Use KNN model\n",
        "# First, choose k=5\n",
        "\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "\n",
        "knn = KNeighborsClassifier(n_neighbors=5)\n",
        "knn.fit(X_train, y_train)\n",
        "\n",
        "#Print accuracy rounded to two digits to the right of decimal\n",
        "print(\"k = 5, knn score=\", knn.score(X_test, y_test))\n",
        "\n",
        "y_pred = knn.predict(X_test) # y_pred includes your predictions\n",
        "\n",
        "# Choose k = 10\n",
        "knn = KNeighborsClassifier(n_neighbors=10)\n",
        "knn.fit(X_train, y_train)\n",
        "\n",
        "#Print accuracy rounded to two digits to the right of decimal\n",
        "print(\"k = 10, knn score =\" , knn.score(X_test, y_test))\n",
        "y_pred = knn.predict(X_test)\n",
        "\n",
        "# Choose k = 15\n",
        "knn = KNeighborsClassifier(n_neighbors=15)\n",
        "knn.fit(X_train, y_train)\n",
        "\n",
        "#Print accuracy rounded to two digits to the right of decimal\n",
        "print(\"k = 15, knn score =\" , knn.score(X_test, y_test))\n",
        "y_pred = knn.predict(X_test)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RR5m0hchPyhq"
      },
      "source": [
        "As we can see from the previous knn score, when k = 15, knn score is the highest. So we will choose k = 15 in the KNN model."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wQqOFKJzR0O4",
        "outputId": "9c610819-815f-445e-fed6-78ae06c0dade"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "KFold with 5:\n",
            "0.7915942028985508\n",
            "KFold with 10:\n",
            "0.7921739130434783\n"
          ]
        }
      ],
      "source": [
        "#import cross validation functions from sk learn\n",
        "\n",
        "from sklearn.model_selection import cross_val_score\n",
        "from sklearn.model_selection import KFold\n",
        "import numpy as np\n",
        "\n",
        "# Set up function parameters for diff't cross validation strategies\n",
        "kfold = KFold(n_splits=5)\n",
        "\n",
        "from statistics import mean \n",
        "\n",
        "print(\"KFold with 5:\\n{}\".format(\n",
        "mean(cross_val_score(KNeighborsClassifier(n_neighbors=15), X_train, y_train, cv=kfold))))\n",
        "\n",
        "kfold = KFold(n_splits=10)\n",
        "\n",
        "from statistics import mean \n",
        "\n",
        "print(\"KFold with 10:\\n{}\".format(\n",
        "mean(cross_val_score(KNeighborsClassifier(n_neighbors=15), X_train, y_train, cv=kfold))))\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Sj6XRnEJUG_x"
      },
      "source": [
        "Here, I will choose n_splits=10 as the parameter of KFold, as it has a better cross_val_score. \n",
        "\n",
        "Also, k=10 was found to provide good trade-off of low computational cost and low bias in an estimate of model performance.(https://machinelearningmastery.com/how-to-configure-k-fold-cross-validation/#:~:text=The%20key%20configuration%20parameter%20for,evaluate%20models%20is%20k%3D10.)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iCXTMEJaSiwP"
      },
      "source": [
        "The best score that KNN model get is 0.8063768115942029."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u4rwoQPFmLlh"
      },
      "source": [
        "9. Choose a second model from question four.  Using the same three variables in the dataset that you think will be good predictors of \"spam\".  Describe why you chose any particular parameters for your model (e.g.- if you used KNN how did you decide to choose a specific value for k).  Run the model and evaluate prediction error in two ways: A) On test data directly and B) using k-fold cross-validation.  Did this model predict test data better than your previous model?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "unmYirFtmplD",
        "outputId": "fbdf79b2-934f-4945-8215-97a60b342b9b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "logreg .coef_: [[1.47909829 2.06454786 3.46998829]]\n",
            "Training set score: 0.748\n",
            "Test set score: 0.784\n",
            "logreg.predict: [0 0 1 ... 0 0 0]\n",
            "logreg .coef_: [[1.47001176 2.03167546 2.87959564]]\n",
            "Training set score: 0.749\n",
            "Test set score: 0.782\n",
            "logreg.predict: [0 0 1 ... 0 0 0]\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "LogisticRegression()"
            ]
          },
          "execution_count": 26,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "#Logistic Regression\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "\n",
        "logreg = LogisticRegression(penalty='none').fit(X_train, y_train)\n",
        "\n",
        "print(\"logreg .coef_: {}\".format(logreg.coef_))\n",
        "\n",
        "\n",
        "print(\"Training set score: {:.3f}\".format(logreg.score(X_train, y_train)))\n",
        "print(\"Test set score: {:.3f}\".format(logreg.score(X_test, y_test)))\n",
        "\n",
        "\n",
        "predicted_vals = logreg.predict(X_test) # y_pred includes your predictions\n",
        "print(\"logreg.predict: {}\".format(predicted_vals))\n",
        "\n",
        "logreg\n",
        "\n",
        "\n",
        "logreg = LogisticRegression(penalty='l2').fit(X_train, y_train)\n",
        "\n",
        "print(\"logreg .coef_: {}\".format(logreg.coef_))\n",
        "\n",
        "\n",
        "print(\"Training set score: {:.3f}\".format(logreg.score(X_train, y_train)))\n",
        "print(\"Test set score: {:.3f}\".format(logreg.score(X_test, y_test)))\n",
        "\n",
        "\n",
        "predicted_vals = logreg.predict(X_test) # y_pred includes your predictions\n",
        "print(\"logreg.predict: {}\".format(predicted_vals))\n",
        "\n",
        "logreg\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gA_pZNLbiSOy",
        "outputId": "bff9769b-e4b6-4c25-fd2d-4795b186de15"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "KFold with 5:\n",
            "0.7515942028985507\n",
            "KFold with 10:\n",
            "0.7495652173913043\n"
          ]
        }
      ],
      "source": [
        "# Use k-fold cross validation\n",
        "\n",
        "kfold = KFold(n_splits=5)\n",
        "\n",
        "print(\"KFold with 5:\\n{}\".format(\n",
        "mean(cross_val_score(LogisticRegression(), X_train, y_train, cv=kfold))))\n",
        "\n",
        "kfold = KFold(n_splits=10)\n",
        "\n",
        "from statistics import mean \n",
        "\n",
        "print(\"KFold with 10:\\n{}\".format(\n",
        "mean(cross_val_score(LogisticRegression(), X_train, y_train, cv=kfold))))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SubM6B7Zizya"
      },
      "source": [
        "Here, we can see that k-fold with 5 has a better cross-validation score. So I will choose k-fold with 5."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vKLIhv7DinZV"
      },
      "source": [
        "The accuracy of Logistic Regression model is 0.752, and the accuracy of k-fold with 5 is 0.7478260869565218. The best score that Logistic Regression get is 0.752, which is lower than the previous model."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aDrsN6E7mLge"
      },
      "source": [
        "10. Choose a third model from question four.  Using the same three variables in the dataset that you think will be good predictors of \"spam\".  Describe why you chose any particular parameters for your model (e.g.- if you used KNN how did you decide to choose a specific value for k). Run the model and evaluate prediction error in two ways: A) On test data directly and B) using k-fold cross-validation.  Did this model predict test data better than your previous models?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "28X47Qnimp1A",
        "outputId": "32471ccf-408a-48ea-cd51-1680d3c6ab7b"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0.8549087749782798"
            ]
          },
          "execution_count": 28,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Decision Tree Classifier\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "\n",
        "tree = DecisionTreeClassifier()\n",
        "\n",
        "model = tree.fit(X,y)\n",
        "\n",
        "model.score(X_test, y_test)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6lU2chjglWD1",
        "outputId": "44603b5e-d1f2-4c26-fd0d-0269e47a4822"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "KFold with 5:\n",
            "0.7756521739130434\n",
            "KFold with 10:\n",
            "0.778840579710145\n"
          ]
        }
      ],
      "source": [
        "# Use k-fold cross validation\n",
        "\n",
        "kfold = KFold(n_splits=5)\n",
        "\n",
        "print(\"KFold with 5:\\n{}\".format(\n",
        "mean(cross_val_score(DecisionTreeClassifier(), X_train, y_train, cv=kfold))))\n",
        "\n",
        "kfold = KFold(n_splits=10)\n",
        "\n",
        "from statistics import mean \n",
        "\n",
        "print(\"KFold with 10:\\n{}\".format(\n",
        "mean(cross_val_score(DecisionTreeClassifier(), X_train, y_train, cv=kfold))))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wrB6D86JrhVW"
      },
      "source": [
        "Here, I will choose n_splits=10 as the parameter of KFold, as it has a better cross_val_score.\n",
        "\n",
        "Also, k=10 was found to provide good trade-off of low computational cost and low bias in an estimate of model performance.(https://machinelearningmastery.com/how-to-configure-k-fold-cross-validation/#:~:text=The%20key%20configuration%20parameter%20for,evaluate%20models%20is%20k%3D10.)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u2OOsGEXs5z7"
      },
      "source": [
        "The accuracy of Logistic Regression model is 0.8427454387489139. With K-fold k = 10, the accuracy is 0.7808695652173914. So the best score that Logistic Regression model get is 0.8427454387489139. This is better than the previous models."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TkLb9uf4mLaI"
      },
      "source": [
        "11. Choose a fourth model from question four.  Using the same three variables in the dataset that you think will be good predictors of \"spam\".  Describe why you chose any particular parameters for your model (e.g.- if you used KNN how did you decide to choose a specific value for k). Run the model and evaluate prediction error in two ways: A) On test data directly and B) using k-fold cross-validation.  Did this model predict test data better than your previous models?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EDbSpV82mqr1",
        "outputId": "a8cfb750-43e2-4062-9238-0e58c480d1b9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "n_estimater = 100, score =  0.8566463944396178\n",
            "n_estimater = 200, score =  0.8531711555169418\n",
            "n_estimater = 300, score =  0.8523023457862728\n",
            "n_estimater = 1000, score =  0.8523023457862728\n"
          ]
        }
      ],
      "source": [
        "# Random Forest Classifier\n",
        "\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "\n",
        "model = RandomForestClassifier(n_estimators=100)\n",
        "\n",
        "#Using make_blobs toy dataset above\n",
        "model.fit(X,y)\n",
        "ypred = model.predict(X_test)\n",
        "print(\"n_estimater = 100, score = \", model.score(X_test,y_test))\n",
        "\n",
        "model = RandomForestClassifier(n_estimators=200)\n",
        "\n",
        "#Using make_blobs toy dataset above\n",
        "model.fit(X,y)\n",
        "ypred = model.predict(X_test)\n",
        "print(\"n_estimater = 200, score = \", model.score(X_test,y_test))\n",
        "\n",
        "model = RandomForestClassifier(n_estimators=300)\n",
        "\n",
        "#Using make_blobs toy dataset above\n",
        "model.fit(X,y)\n",
        "ypred = model.predict(X_test)\n",
        "print(\"n_estimater = 300, score = \", model.score(X_test,y_test))\n",
        "\n",
        "model = RandomForestClassifier(n_estimators=1000)\n",
        "\n",
        "#Using make_blobs toy dataset above\n",
        "model.fit(X,y)\n",
        "ypred = model.predict(X_test)\n",
        "print(\"n_estimater = 1000, score = \", model.score(X_test,y_test))\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lr-rcMwPrH1i"
      },
      "source": [
        "Here, we can find out that when n_estimater = 1000, the model has the highest score. So I will choose n_estimater to be 1000."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eIPohe5OmSet",
        "outputId": "555a0a07-877f-4ce2-9b50-e8f5c0bca8a4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "KFold with 5:\n",
            "0.7846376811594203\n",
            "KFold with 10:\n",
            "0.7855072463768116\n"
          ]
        }
      ],
      "source": [
        "# Using k-fold cross-validation\n",
        "kfold = KFold(n_splits=5)\n",
        "\n",
        "print(\"KFold with 5:\\n{}\".format(\n",
        "mean(cross_val_score(RandomForestClassifier(n_estimators=200), X_train, y_train, cv=kfold))))\n",
        "\n",
        "kfold = KFold(n_splits=10)\n",
        "\n",
        "from statistics import mean \n",
        "\n",
        "print(\"KFold with 10:\\n{}\".format(\n",
        "mean(cross_val_score(RandomForestClassifier(n_estimators=200), X_train, y_train, cv=kfold))))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W4eyZHiTrYSV"
      },
      "source": [
        "Here, I will choose n_splits=10 as the parameter of KFold, as it has a better cross_val_score.\n",
        "\n",
        "Also, k=10 was found to provide good trade-off of low computational cost and low bias in an estimate of model performance.(https://machinelearningmastery.com/how-to-configure-k-fold-cross-validation/#:~:text=The%20key%20configuration%20parameter%20for,evaluate%20models%20is%20k%3D10.)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4fY37HTItSXu"
      },
      "source": [
        "The accuracy of Random Forest Classifier is 0.840139009556907 when n_estimater = 1000. With k-fold = 10, the accuracy is 0.7936231884057972. The best score of Random Forest Classifier is 0.840139009556907. This is lower than the Logistic Regression model."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JsgBJaztmLPp"
      },
      "source": [
        "12. Now rerun your best model from questions 8 through 11, but this time add three new variables to the model that you think will increase prediction accuracy.   Did this model predict test data better than your previous models?\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LZCfiCPG9WBW"
      },
      "source": [
        "I will now add three variables to the model: \"word_freq_receive:\", \"word_freq_our:\", \"word_freq_mail:\", and use the Logistic Regression Model."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YBmDtu-N9VfL",
        "outputId": "20b2a4c9-a459-4989-96cf-66705cbd550f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "0       1\n",
            "1       1\n",
            "2       1\n",
            "3       1\n",
            "4       1\n",
            "       ..\n",
            "4596    0\n",
            "4597    0\n",
            "4598    0\n",
            "4599    0\n",
            "4600    0\n",
            "Name: spam, Length: 4601, dtype: int64\n",
            "      word_freq_order:  word_freq_free:  word_freq_credit:  \\\n",
            "0                 0.00             0.32               0.00   \n",
            "1                 0.00             0.14               0.00   \n",
            "2                 0.64             0.06               0.32   \n",
            "3                 0.31             0.31               0.00   \n",
            "4                 0.31             0.31               0.00   \n",
            "...                ...              ...                ...   \n",
            "4596              0.00             0.00               0.00   \n",
            "4597              0.00             0.00               0.00   \n",
            "4598              0.00             0.00               0.00   \n",
            "4599              0.00             0.00               0.00   \n",
            "4600              0.00             0.00               0.00   \n",
            "\n",
            "      word_freq_receive:  word_freq_our:  word_freq_mail:  \n",
            "0                   0.00            0.32             0.00  \n",
            "1                   0.21            0.14             0.94  \n",
            "2                   0.38            1.23             0.25  \n",
            "3                   0.31            0.63             0.63  \n",
            "4                   0.31            0.63             0.63  \n",
            "...                  ...             ...              ...  \n",
            "4596                0.00            0.00             0.00  \n",
            "4597                0.00            0.00             0.00  \n",
            "4598                0.00            0.00             0.00  \n",
            "4599                0.00            0.32             0.00  \n",
            "4600                0.00            0.00             0.00  \n",
            "\n",
            "[4601 rows x 6 columns]\n"
          ]
        }
      ],
      "source": [
        "# Add the three variables to the model\n",
        "y1 = df['spam']\n",
        "print(y1)\n",
        "\n",
        "X1 = df.loc[:, lambda df:[\"word_freq_order:\",\"word_freq_free:\",\"word_freq_credit:\",\"word_freq_receive:\", \"word_freq_our:\", \"word_freq_mail:\"]]\n",
        "print(X1)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B6A66TDu-Fhr",
        "outputId": "43a6e408-79b0-44a6-8923-c689c32c3971"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(4601, 6)\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "(3450, 6)"
            ]
          },
          "execution_count": 33,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Train test split\n",
        "\n",
        "# Use train_test_split(X,y) to create four new data sets, defaults to .75/.25 split\n",
        "X1_train, X1_test, y1_train, y1_test = train_test_split(X1, y1)\n",
        "\n",
        "print(X1.shape)\n",
        "X1_train.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bZQ6FzN6-R50",
        "outputId": "a52ef18f-8f33-48f7-9f26-636b65431317"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "logreg .coef_: [[1.82485897 1.28933893 2.29945436 2.28592648 0.79260328 0.33568805]]\n",
            "Training set score: 0.774\n",
            "Test set score: 0.759\n",
            "logreg.predict: [0 0 1 ... 0 0 0]\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "LogisticRegression(penalty='none')"
            ]
          },
          "execution_count": 34,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "#Logistic Regression\n",
        "\n",
        "logreg = LogisticRegression(penalty='none').fit(X1_train, y1_train)\n",
        "\n",
        "print(\"logreg .coef_: {}\".format(logreg.coef_))\n",
        "\n",
        "\n",
        "print(\"Training set score: {:.3f}\".format(logreg.score(X1_train, y1_train)))\n",
        "print(\"Test set score: {:.3f}\".format(logreg.score(X1_test, y1_test)))\n",
        "\n",
        "\n",
        "predicted_vals = logreg.predict(X1_test) # y_pred includes your predictions\n",
        "print(\"logreg.predict: {}\".format(predicted_vals))\n",
        "\n",
        "logreg"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ejwMs7k3-ZtN",
        "outputId": "39447578-bcb6-4b4e-8a56-4c25854f3954"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "KFold with 5:\n",
            "0.7753623188405797\n",
            "KFold with 10:\n",
            "0.7727536231884058\n"
          ]
        }
      ],
      "source": [
        "# Use k-fold cross validation\n",
        "\n",
        "kfold = KFold(n_splits=5)\n",
        "\n",
        "print(\"KFold with 5:\\n{}\".format(\n",
        "mean(cross_val_score(LogisticRegression(), X1_train, y1_train, cv=kfold))))\n",
        "\n",
        "kfold = KFold(n_splits=10)\n",
        "\n",
        "from statistics import mean \n",
        "\n",
        "print(\"KFold with 10:\\n{}\".format(\n",
        "mean(cross_val_score(LogisticRegression(), X1_train, y1_train, cv=kfold))))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "biCfLTW2-ktt"
      },
      "source": [
        "No. This time the highest score of the model is 0.770 which is lower than the previous model."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "57sx4NMLmKyj"
      },
      "source": [
        "13. Rerun all your other models with this final set of six variables, evaluate prediction error, and choose a final model.  Why did you select this model among all of the models that you ran?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n_iHxJrz_Ela"
      },
      "source": [
        "**KNN model**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Em-CuHYg-61F",
        "outputId": "d75edbad-4143-4e16-835c-f51638e51704"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "k = 5, knn score= 0.8053866203301477\n",
            "k = 10, knn score = 0.8010425716768028\n",
            "k = 15, knn score = 0.787141615986099\n"
          ]
        }
      ],
      "source": [
        "# Use KNN model\n",
        "# First, choose k=5\n",
        "\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "\n",
        "knn = KNeighborsClassifier(n_neighbors=5)\n",
        "knn.fit(X1_train, y1_train)\n",
        "\n",
        "#Print accuracy rounded to two digits to the right of decimal\n",
        "print(\"k = 5, knn score=\", knn.score(X1_test, y1_test))\n",
        "\n",
        "y_pred = knn.predict(X1_test) # y_pred includes your predictions\n",
        "\n",
        "# Choose k = 10\n",
        "knn = KNeighborsClassifier(n_neighbors=10)\n",
        "knn.fit(X1_train, y1_train)\n",
        "\n",
        "#Print accuracy rounded to two digits to the right of decimal\n",
        "print(\"k = 10, knn score =\" , knn.score(X1_test, y1_test))\n",
        "y_pred = knn.predict(X1_test)\n",
        "\n",
        "# Choose k = 15\n",
        "knn = KNeighborsClassifier(n_neighbors=15)\n",
        "knn.fit(X1_train, y1_train)\n",
        "\n",
        "#Print accuracy rounded to two digits to the right of decimal\n",
        "print(\"k = 15, knn score =\" , knn.score(X1_test, y1_test))\n",
        "y_pred = knn.predict(X1_test)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CBJ3XF55A_nw"
      },
      "source": [
        "Here, choose k=5 since it has the highest score."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "D3NvdwVD_UvG",
        "outputId": "e4cb11b7-6def-41cd-f189-90038787620b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "KFold with 5:\n",
            "0.8173913043478261\n",
            "KFold with 10:\n",
            "0.8202898550724638\n"
          ]
        }
      ],
      "source": [
        "# Set up function parameters for diff't cross validation strategies\n",
        "kfold = KFold(n_splits=5)\n",
        "\n",
        "print(\"KFold with 5:\\n{}\".format(\n",
        "mean(cross_val_score(KNeighborsClassifier(n_neighbors=5), X1_train, y1_train, cv=kfold))))\n",
        "\n",
        "kfold = KFold(n_splits=10)\n",
        "\n",
        "print(\"KFold with 10:\\n{}\".format(\n",
        "mean(cross_val_score(KNeighborsClassifier(n_neighbors=5), X1_train, y1_train, cv=kfold))))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xFaxwmYP_fWg"
      },
      "source": [
        "The best score of KNN is 0.8188405797101449."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-Etjunwb_kHl"
      },
      "source": [
        "**Random Forest**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kzfh6Dr3ABOE",
        "outputId": "99a4b6cb-afbf-4a6e-8981-be1243bc2d36"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "n_estimater = 100, score =  0.9061685490877498\n",
            "n_estimater = 200, score =  0.9026933101650738\n",
            "n_estimater = 300, score =  0.9035621198957429\n",
            "n_estimater = 1000, score =  0.9035621198957429\n"
          ]
        }
      ],
      "source": [
        "# Random Forest Classifier\n",
        "\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "\n",
        "model = RandomForestClassifier(n_estimators=100)\n",
        "\n",
        "#Using make_blobs toy dataset above\n",
        "model.fit(X1,y1)\n",
        "ypred = model.predict(X1_test)\n",
        "print(\"n_estimater = 100, score = \", model.score(X1_test,y1_test))\n",
        "\n",
        "model = RandomForestClassifier(n_estimators=200)\n",
        "\n",
        "#Using make_blobs toy dataset above\n",
        "model.fit(X1,y1)\n",
        "ypred = model.predict(X1_test)\n",
        "print(\"n_estimater = 200, score = \", model.score(X1_test,y1_test))\n",
        "\n",
        "model = RandomForestClassifier(n_estimators=300)\n",
        "\n",
        "#Using make_blobs toy dataset above\n",
        "model.fit(X1,y1)\n",
        "ypred = model.predict(X1_test)\n",
        "print(\"n_estimater = 300, score = \", model.score(X1_test,y1_test))\n",
        "\n",
        "model = RandomForestClassifier(n_estimators=1000)\n",
        "\n",
        "#Using make_blobs toy dataset above\n",
        "model.fit(X1,y1)\n",
        "ypred = model.predict(X1_test)\n",
        "print(\"n_estimater = 1000, score = \", model.score(X1_test,y1_test))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H-MdrPRnBFyI"
      },
      "source": [
        "Here, choose n_estimater = 300 since it has the highest score."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uY_9araWABey",
        "outputId": "f03527f3-e389-4f8d-b035-4580031fa333"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "KFold with 5:\n",
            "0.8156521739130435\n",
            "KFold with 10:\n",
            "0.8205797101449276\n"
          ]
        }
      ],
      "source": [
        "# Using k-fold cross-validation\n",
        "kfold = KFold(n_splits=5)\n",
        "\n",
        "print(\"KFold with 5:\\n{}\".format(\n",
        "mean(cross_val_score(RandomForestClassifier(n_estimators=300), X1_train, y1_train, cv=kfold))))\n",
        "\n",
        "kfold = KFold(n_splits=10)\n",
        "\n",
        "print(\"KFold with 10:\\n{}\".format(\n",
        "mean(cross_val_score(RandomForestClassifier(n_estimators=300), X1_train, y1_train, cv=kfold))))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZlndfHmcAhdO"
      },
      "source": [
        "The best score of Random Forest is 0.9044309296264118."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MSf6ZiCm_qb9"
      },
      "source": [
        "**Decision Tree**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Gy6HFksd_saR",
        "outputId": "68804074-8df0-406e-e32c-18bf5db73762"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0.9026933101650738"
            ]
          },
          "execution_count": 40,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Decision Tree Classifier\n",
        "tree = DecisionTreeClassifier()\n",
        "\n",
        "model = tree.fit(X1,y1)\n",
        "\n",
        "model.score(X1_test, y1_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xvgr-sED_1K1",
        "outputId": "2c5e2834-705b-43d3-dccc-21d24b859a84"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "KFold with 5:\n",
            "0.8049275362318841\n",
            "KFold with 10:\n",
            "0.8098550724637681\n"
          ]
        }
      ],
      "source": [
        "# Use k-fold cross validation\n",
        "\n",
        "kfold = KFold(n_splits=5) # add a comment on why you chose this specific parameter. \n",
        "\n",
        "print(\"KFold with 5:\\n{}\".format(\n",
        "mean(cross_val_score(DecisionTreeClassifier(), X1_train, y1_train, cv=kfold))))\n",
        "\n",
        "kfold = KFold(n_splits=10) # add a comment on why you chose this specific parameter.\n",
        "\n",
        "print(\"KFold with 10:\\n{}\".format(\n",
        "mean(cross_val_score(DecisionTreeClassifier(), X1_train, y1_train, cv=kfold))))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KorDXp5__9Bb"
      },
      "source": [
        "The best score of Decision Tree is 0.9061685490877498."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TVfvGk0UA21a"
      },
      "source": [
        "Overall, I will choose Decision Tree classifier as the final model, without k-fold. This model has the highest score with the 6 variables."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dfz55IVjmimp"
      },
      "source": [
        "14. What variable that currently is not in your model, if included, would be likely to increase your final model's predictive power?  For this answer try to speculate about a variable outside the variables available in the data that would improve you model."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gGw-9wsKRC20"
      },
      "source": [
        "I think the the word \"shop\" might also be a word that appears frequently in spam emails as spam emails always ask people to buy something. So the variable \"word_freq_shop\" might increase the final model's predictive power."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xsjXO2NAmi2e"
      },
      "source": [
        "15. Lastly, you have listed each of the models that we have learned to use to predict dependent variables like spam.  List each model we have focused on in class thus far that you could use to evaluate data with a continuous dependent variable. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Xx955WK0RA0r"
      },
      "source": [
        "Supervised Learning Models:\n",
        "1. K Nearest Neighbors:KNN\n",
        "2. Ridge Regression\n",
        "3. Lasso Regression\n",
        "4. Linear Regression\n",
        "5. Logistic Regression\n",
        "6. Support Vector Machines\n",
        "7. Random Forests\n",
        "8. Decision Tree\n",
        "9. Bagging"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
